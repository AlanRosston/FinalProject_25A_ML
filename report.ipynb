{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e905718",
   "metadata": {},
   "source": [
    "# Part 1 项目介绍\n",
    "\n",
    "## 1.1 项目背景\n",
    "CIFAR-10是一个经典的计算机视觉数据集,包含10个类别的60000张32x32彩色图像,其中训练集50000张,测试集10000张。这10个类别分别是:飞机(airplane)、汽车(automobile)、鸟(bird)、猫(cat)、鹿(deer)、狗(dog)、青蛙(frog)、马(horse)、船(ship)和卡车(truck)。\n",
    "\n",
    "## 1.2 项目目标\n",
    "\n",
    "本项目旨在对比传统机器学习方法和深度学习方法在图像分类任务上的性能差异:\n",
    "\n",
    "1. **传统方法**: 使用HOG特征提取 + PCA降维 + SVM分类器\n",
    "2. **深度学习方法**: 使用卷积神经网络(CNN)\n",
    "\n",
    "通过对比实验,我们将分析两种方法在准确率、训练时间等方面的差异,深入理解深度学习相比传统方法的优势。\n",
    "\n",
    "## 1.3 技术路线\n",
    "\n",
    "- **Part 2**: 特征提取和降维(HOG + PCA + t-SNE可视化)\n",
    "- **Part 3**: 传统模型实验(SVM分类器)\n",
    "- **Part 4**: 深度模型实验(CNN)\n",
    "- **Part 5**: 总结与对比分析"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83228611",
   "metadata": {},
   "source": [
    "# Part 2 特征提取和降维\n",
    "\n",
    "本部分将提取图像的HOG特征并进行降维处理,为后续的传统机器学习模型做准备。\n",
    "\n",
    "## 2.1 特征提取\n",
    "\n",
    "### 2.1.1 HOG特征介绍\n",
    "\n",
    "**HOG (Histogram of Oriented Gradients)**,即方向梯度直方图,是一种在计算机视觉和图像处理中用来进行物体检测的特征描述子。\n",
    "\n",
    "**基本原理**:\n",
    "1. **梯度计算**: 计算图像中每个像素的梯度方向和幅值\n",
    "2. **单元格划分**: 将图像划分为小的单元格(cells)\n",
    "3. **方向直方图**: 在每个单元格内统计梯度方向的直方图\n",
    "4. **块归一化**: 将相邻的单元格组成块(blocks),并进行归一化\n",
    "\n",
    "**优点**:\n",
    "- 对光照变化不敏感\n",
    "- 能够捕捉边缘和形状信息\n",
    "- 具有良好的几何不变性\n",
    "\n",
    "**参数设置**:\n",
    "- `orientations=9`: 梯度方向被分为9个bin\n",
    "- `pixels_per_cell=(8, 8)`: 每个单元格为8x8像素\n",
    "- `cells_per_block=(2, 2)`: 每个块包含2x2个单元格"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75545b70",
   "metadata": {},
   "source": [
    "### 2.1.2 提取HOG特征\n",
    "数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc76c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import os\n",
    "from skimage.feature import hog\n",
    "from skimage import color\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 设置随机种子以确保结果可复现\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"库导入成功!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf481844",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载训练数据标签\n",
    "data_dir = 'Data/cifar-10'\n",
    "train_labels_df = pd.read_csv(os.path.join(data_dir, 'trainLabels.csv'))\n",
    "\n",
    "print(f\"训练集样本数: {len(train_labels_df)}\")\n",
    "print(f\"\\n类别分布:\")\n",
    "print(train_labels_df['label'].value_counts())\n",
    "print(f\"\\n前5行数据:\")\n",
    "print(train_labels_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cbf02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化部分样本\n",
    "fig, axes = plt.subplots(2, 5, figsize=(12, 5))\n",
    "fig.suptitle('CIFAR-10 样本展示', fontsize=16)\n",
    "\n",
    "# 随机选择10个样本\n",
    "sample_ids = np.random.choice(train_labels_df['id'].values, 10, replace=False)\n",
    "\n",
    "for idx, (ax, img_id) in enumerate(zip(axes.flatten(), sample_ids)):\n",
    "    img_path = os.path.join(data_dir, 'train', f'{img_id}.png')\n",
    "    img = Image.open(img_path)\n",
    "    label = train_labels_df[train_labels_df['id'] == img_id]['label'].values[0]\n",
    "    \n",
    "    ax.imshow(img)\n",
    "    ax.set_title(f'{label}', fontsize=10)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2037a89e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义HOG特征提取函数\n",
    "def extract_hog_features(image, orientations=9, pixels_per_cell=(8, 8), cells_per_block=(2, 2)):\n",
    "    \"\"\"\n",
    "    提取图像的HOG特征\n",
    "    \n",
    "    参数:\n",
    "        image: RGB图像 (H, W, 3)\n",
    "        orientations: 梯度方向的bin数量\n",
    "        pixels_per_cell: 每个cell的像素大小\n",
    "        cells_per_block: 每个block包含的cell数量\n",
    "    \n",
    "    返回:\n",
    "        hog_features: HOG特征向量\n",
    "    \"\"\"\n",
    "    # 将RGB图像转换为灰度图\n",
    "    if len(image.shape) == 3:\n",
    "        gray_image = color.rgb2gray(image)\n",
    "    else:\n",
    "        gray_image = image\n",
    "    \n",
    "    # 提取HOG特征\n",
    "    hog_features = hog(gray_image, \n",
    "                       orientations=orientations,\n",
    "                       pixels_per_cell=pixels_per_cell,\n",
    "                       cells_per_block=cells_per_block,\n",
    "                       visualize=False,\n",
    "                       feature_vector=True)\n",
    "    \n",
    "    return hog_features\n",
    "\n",
    "# 测试HOG特征提取\n",
    "test_img_path = os.path.join(data_dir, 'train', '1.png')\n",
    "test_img = np.array(Image.open(test_img_path))\n",
    "test_hog = extract_hog_features(test_img)\n",
    "\n",
    "print(f\"原始图像形状: {test_img.shape}\")\n",
    "print(f\"HOG特征维度: {test_hog.shape}\")\n",
    "print(f\"HOG特征前10个值: {test_hog[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e817b039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量提取HOG特征\n",
    "# 为了演示,我们使用前10000个样本(可以调整以使用全部数据)\n",
    "n_samples = 10000  # 使用前10000个样本进行演示,完整实验可设为50000\n",
    "\n",
    "print(f\"开始提取 {n_samples} 个样本的HOG特征...\")\n",
    "\n",
    "hog_features_list = []\n",
    "labels_list = []\n",
    "\n",
    "for i in range(n_samples):\n",
    "    if (i + 1) % 1000 == 0:\n",
    "        print(f\"已处理: {i + 1}/{n_samples}\")\n",
    "    \n",
    "    # 获取图像ID和标签\n",
    "    img_id = train_labels_df.iloc[i]['id']\n",
    "    label = train_labels_df.iloc[i]['label']\n",
    "    \n",
    "    # 加载图像\n",
    "    img_path = os.path.join(data_dir, 'train', f'{img_id}.png')\n",
    "    img = np.array(Image.open(img_path))\n",
    "    \n",
    "    # 提取HOG特征\n",
    "    hog_feat = extract_hog_features(img)\n",
    "    \n",
    "    hog_features_list.append(hog_feat)\n",
    "    labels_list.append(label)\n",
    "\n",
    "# 转换为numpy数组\n",
    "X_hog = np.array(hog_features_list)\n",
    "y = np.array(labels_list)\n",
    "\n",
    "print(f\"\\n特征提取完成!\")\n",
    "print(f\"HOG特征矩阵形状: {X_hog.shape}\")\n",
    "print(f\"标签数组形状: {y.shape}\")\n",
    "print(f\"\\n类别分布:\")\n",
    "unique, counts = np.unique(y, return_counts=True)\n",
    "for label, count in zip(unique, counts):\n",
    "    print(f\"  {label}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac083c2",
   "metadata": {},
   "source": [
    "## 2.2 降维\n",
    "\n",
    "本部分使用**PCA**进行降维，然后使用**t-SNE**进行可视化。可视化将会使用PCA降维到50维的预处理数据"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca300c",
   "metadata": {},
   "source": [
    "### 2.2.1 PCA和t-SNE介绍\n",
    "\n",
    "#### PCA (主成分分析)\n",
    "\n",
    "**PCA (Principal Component Analysis)** 是一种经典的降维技术,通过线性变换将高维数据投影到低维空间。\n",
    "\n",
    "**基本原理**:\n",
    "1. 计算数据的协方差矩阵\n",
    "2. 求解协方差矩阵的特征值和特征向量\n",
    "3. 选择最大的k个特征值对应的特征向量\n",
    "4. 将数据投影到这k个特征向量张成的空间\n",
    "\n",
    "**优点**:\n",
    "- 计算效率高\n",
    "- 能够保留数据的主要方差信息\n",
    "- 去除数据冗余和噪声\n",
    "\n",
    "**应用**:\n",
    "- 第一次降维:将HOG特征降到50维,用于t-SNE可视化\n",
    "- 第二次降维:保留95%的方差,用于SVM分类\n",
    "\n",
    "#### t-SNE (t分布随机邻域嵌入)\n",
    "\n",
    "**t-SNE (t-Distributed Stochastic Neighbor Embedding)** 是一种非线性降维算法,特别适合高维数据的可视化。\n",
    "\n",
    "**基本原理**:\n",
    "1. 在高维空间中,计算样本点之间的相似度\n",
    "2. 在低维空间中,寻找一个映射使得点之间的相似度分布尽可能接近高维空间\n",
    "3. 使用t分布来建模低维空间中的相似度\n",
    "\n",
    "**优点**:\n",
    "- 能够很好地保持数据的局部结构\n",
    "- 适合将高维数据可视化到2D或3D空间\n",
    "- 能够揭示数据的聚类结构\n",
    "\n",
    "**注意**:\n",
    "- 计算开销较大,通常先用PCA降维再使用t-SNE\n",
    "- 结果受随机初始化影响,需要设置随机种子"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5b21b3",
   "metadata": {},
   "source": [
    "### 2.2.2 PCA降维\n",
    "\n",
    "第一部分降维，需要将原始维度压缩到50维，然后用于t-SNE可视化\n",
    "\n",
    "第二部分降维，需要将原始数据的信息保留$95\\%$左右，然后用于Part 3 的SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7562d096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一次PCA降维: 降到50维,用于t-SNE可视化\n",
    "print(\"=\" * 60)\n",
    "print(\"第一次PCA降维: 降到50维 (用于t-SNE可视化)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pca_50 = PCA(n_components=50, random_state=42)\n",
    "X_pca_50 = pca_50.fit_transform(X_hog)\n",
    "\n",
    "# 计算解释的方差比例\n",
    "explained_variance_ratio_50 = pca_50.explained_variance_ratio_\n",
    "cumulative_variance_ratio_50 = np.cumsum(explained_variance_ratio_50)\n",
    "\n",
    "print(f\"\\n降维后的形状: {X_pca_50.shape}\")\n",
    "print(f\"保留的总方差比例: {cumulative_variance_ratio_50[-1]:.4f} ({cumulative_variance_ratio_50[-1]*100:.2f}%)\")\n",
    "print(f\"前10个主成分的方差比例: {explained_variance_ratio_50[:10]}\")\n",
    "\n",
    "# 可视化方差解释比例\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 4))\n",
    "\n",
    "# 单个主成分的方差比例\n",
    "ax1.bar(range(1, 51), explained_variance_ratio_50)\n",
    "ax1.set_xlabel('主成分编号')\n",
    "ax1.set_ylabel('方差解释比例')\n",
    "ax1.set_title('各主成分的方差解释比例')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 累积方差解释比例\n",
    "ax2.plot(range(1, 51), cumulative_variance_ratio_50, 'b-', marker='o', markersize=3)\n",
    "ax2.set_xlabel('主成分数量')\n",
    "ax2.set_ylabel('累积方差解释比例')\n",
    "ax2.set_title('累积方差解释比例')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.axhline(y=0.95, color='r', linestyle='--', label='95%方差线')\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa0c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二次PCA降维: 保留95%的方差,用于SVM分类\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"第二次PCA降维: 保留95%的方差 (用于SVM分类)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "pca_95 = PCA(n_components=0.95, random_state=42)\n",
    "X_pca_95 = pca_95.fit_transform(X_hog)\n",
    "\n",
    "# 计算解释的方差比例\n",
    "explained_variance_ratio_95 = pca_95.explained_variance_ratio_\n",
    "cumulative_variance_ratio_95 = np.cumsum(explained_variance_ratio_95)\n",
    "\n",
    "print(f\"\\n降维后的维度: {X_pca_95.shape[1]}\")\n",
    "print(f\"降维后的形状: {X_pca_95.shape}\")\n",
    "print(f\"保留的总方差比例: {cumulative_variance_ratio_95[-1]:.4f} ({cumulative_variance_ratio_95[-1]*100:.2f}%)\")\n",
    "print(f\"维度压缩率: {X_pca_95.shape[1] / X_hog.shape[1]:.4f} ({X_pca_95.shape[1] / X_hog.shape[1] * 100:.2f}%)\")\n",
    "\n",
    "# 可视化\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "ax.plot(range(1, len(cumulative_variance_ratio_95) + 1), cumulative_variance_ratio_95, 'b-', marker='o', markersize=2)\n",
    "ax.set_xlabel('主成分数量')\n",
    "ax.set_ylabel('累积方差解释比例')\n",
    "ax.set_title(f'PCA降维 (保留95%方差, 最终维度: {X_pca_95.shape[1]})')\n",
    "ax.grid(True, alpha=0.3)\n",
    "ax.axhline(y=0.95, color='r', linestyle='--', label='95%方差线')\n",
    "ax.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n✓ PCA降维完成,数据已准备好用于后续的SVM分类器训练\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3824988",
   "metadata": {},
   "source": [
    "### 2.2.3 t-SNE可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ffe8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用t-SNE将50维数据降到2维进行可视化\n",
    "print(\"=\" * 60)\n",
    "print(\"t-SNE降维可视化\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n注意: t-SNE计算可能需要几分钟时间...\")\n",
    "\n",
    "# 为了加速演示,我们可以使用部分数据进行t-SNE可视化\n",
    "# 完整实验可以使用全部数据\n",
    "n_tsne_samples = 5000  # 使用5000个样本进行t-SNE可视化\n",
    "\n",
    "# 随机选择样本\n",
    "np.random.seed(42)\n",
    "indices = np.random.choice(len(X_pca_50), n_tsne_samples, replace=False)\n",
    "X_tsne_input = X_pca_50[indices]\n",
    "y_tsne = y[indices]\n",
    "\n",
    "print(f\"使用 {n_tsne_samples} 个样本进行t-SNE可视化\")\n",
    "print(f\"输入数据形状: {X_tsne_input.shape}\")\n",
    "\n",
    "# 应用t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=42, perplexity=30, n_iter=1000)\n",
    "X_tsne = tsne.fit_transform(X_tsne_input)\n",
    "\n",
    "print(f\"t-SNE降维后的形状: {X_tsne.shape}\")\n",
    "print(\"✓ t-SNE降维完成\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6b31d3",
   "metadata": {},
   "source": [
    "# Part 3 传统模型实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ff195b",
   "metadata": {},
   "source": [
    "# Part 4 深度模型实验"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984cea2f",
   "metadata": {},
   "source": [
    "# Part 5 总结"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
